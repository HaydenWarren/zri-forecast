{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c7857b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import helper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fedf305d",
   "metadata": {},
   "source": [
    "#### getting list of different metros zips to split model if necessary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9de8c402",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# lists of relevent zipcodes\n",
    "target_zips = pd.read_csv('target.csv', index_col = 0)\n",
    "houston_zips_list = list(target_zips[target_zips['City']=='Houston']['zip_code'].unique())\n",
    "paso_zips_list = list(target_zips[target_zips['City']=='El Paso']['zip_code'].unique())\n",
    "san_zips_list = list(target_zips[target_zips['City']=='San Antonio']['zip_code'].unique())\n",
    "austin_zips_list = list(target_zips[target_zips['City']=='Austin']['zip_code'].unique())\n",
    "dallas_zips_list = list(target_zips[target_zips['City']=='Dallas-Fort Worth']['zip_code'].unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd6202b",
   "metadata": {},
   "source": [
    "#### Loading and processing data to put into model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aea39826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "texas_data = pd.read_csv('merged_texas_data.csv', index_col = 0,\n",
    "                   parse_dates = ['Time']\n",
    "                  )\n",
    "\n",
    "acs_data = pd.read_csv('merged_acs_data.csv', index_col = 0,\n",
    "                      parse_dates = ['Time'])\n",
    "\n",
    "zri = pd.read_csv('long_interpolated_target.csv', index_col = 0,\n",
    "                   parse_dates=['Time']\n",
    "                  )\n",
    "#'new_feature'\n",
    "# adding shift to zri\n",
    "zri_shift = helper.time_lag_merge(zri, zri, {\n",
    "    12:['zori_ssa',#'new_feature'\n",
    "       ],\n",
    "    13:['zori_ssa'],\n",
    "    18:['zori_ssa'],\n",
    "    24:['zori_ssa']\n",
    "},\n",
    "                                          return_full = True\n",
    "                                         )\n",
    "\n",
    "# there should now be extra values after our target. \n",
    "# We are gonna remove the missing values that happen at the start of our inputs tho\n",
    "zri_shift = zri_shift.sort_values('Time')\n",
    "zri_shift = zri_shift.dropna(subset = ['zori_ssa_24_month_shift'],axis='index',\n",
    "                             how = 'any').reset_index(drop = True)\n",
    "# Adding the shift values\n",
    "zri_shift.loc[:,'zori_ssa_1_diff_lag_12'] = (zri_shift.loc[:,'zori_ssa_12_month_shift'] -\n",
    "                                             zri_shift.loc[:,'zori_ssa_13_month_shift'])\n",
    "zri_shift.loc[:,'zori_ssa_6_diff_lag_12'] = (zri_shift.loc[:,'zori_ssa_12_month_shift'] -\n",
    "                                             zri_shift.loc[:,'zori_ssa_18_month_shift'])\n",
    "zri_shift.loc[:,'zori_ssa_12_diff_lag_12'] = (zri_shift.loc[:,'zori_ssa_12_month_shift'] -\n",
    "                                             zri_shift.loc[:,'zori_ssa_24_month_shift'])\n",
    "zri_shift['zori_ssa_12_diff_lag_12_per'] = (zri_shift['zori_ssa_12_diff_lag_12']/\n",
    "                                           zri_shift['zori_ssa_12_month_shift'])\n",
    "\n",
    "zri_shift = zri_shift[['Time','zip_code','zori_ssa', #'new_feature'\n",
    "                       'zori_ssa_12_month_shift',\n",
    "                       'zori_ssa_1_diff_lag_12', \n",
    "                       'zori_ssa_6_diff_lag_12',\n",
    "                       'zori_ssa_12_diff_lag_12_per'\n",
    "                      ]]\n",
    "\n",
    "\n",
    "# merge non acs data \n",
    "extra_shift = ['Gross Value Natural Gas Production', 'sap_case_shiller_index']\n",
    "merged_df = helper.time_lag_merge(zri_shift, \n",
    "                                                    texas_data, {\n",
    "    12:list(texas_data.drop(columns = ['Time','zip_code']+extra_shift\n",
    "                            ).columns),\n",
    "    13:extra_shift\n",
    "},\n",
    "                                          return_full = True\n",
    "                                         )\n",
    "# merge acs data\n",
    "acs_1_cols = [\n",
    "    'black_pop',\n",
    "    'white_pop',\n",
    "    'hispanic_pop',\n",
    "    'high_school_diploma',\n",
    "    'female_female_households',\n",
    "    'armed_forces',\n",
    "    'children',\n",
    "    'black_pop_annual_pct_change',\n",
    "    'white_pop_annual_pct_change',\n",
    "    'hispanic_pop_annual_pct_change',\n",
    "    'high_school_diploma_annual_pct_change',\n",
    "    'children_annual_pct_change',\n",
    "    ]\n",
    "merged_df = helper.time_lag_merge(merged_df, \n",
    "                                                    acs_data, {\n",
    "    36:list(acs_data.drop(columns = ['Time','zip_code'] + acs_1_cols).columns),\n",
    "    48:acs_1_cols                                              \n",
    "},\n",
    "                                          return_full = True\n",
    "                                         )\n",
    "# # visualize missing values. it should be that acs 2 does not have a single zipcode\n",
    "# # then removing that line and checking to see that there are no more missing values.\n",
    "merged_df = merged_df.loc[merged_df['Time']>datetime.datetime(2016,6,2),:\n",
    "                          ].reset_index(drop=True)\n",
    "merged_df = merged_df.loc[merged_df['Time']<datetime.datetime(2022,7,2),:\n",
    "                          ].reset_index(drop=True)\n",
    "merged_df = merged_df.sort_values('Time')\n",
    "merged_df = merged_df.dropna(subset = ['single_women_36_month_shift'],axis='index',\n",
    "                             how = 'any').reset_index(drop = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021d34a8",
   "metadata": {},
   "source": [
    "#### Adding net approve feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbe5c512",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['tx_net_approve_12_month_shift'] = (merged_df['tx_is_better_12_month_shift'] - \n",
    "                                              merged_df['tx_is_worse_12_month_shift'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6044384e",
   "metadata": {},
   "source": [
    "#### Features to put into model. Splitting test, train, forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85e1874b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating list of variables to put into the model. initialy is all non index and target\n",
    "X_vals = [\n",
    "    'zori_ssa_12_month_shift',\n",
    "    'zori_ssa_1_diff_lag_12',\n",
    "    'zori_ssa_6_diff_lag_12',\n",
    "    'total_sales_tax_12_month_shift',\n",
    "    'housing_units_over_50_units_36_month_shift',\n",
    "    'housing_units_built_1960_to_1969_36_month_shift',\n",
    "    'black_pop_48_month_shift',\n",
    "    'zori_ssa_12_diff_lag_12_per',\n",
    "    'children_annual_pct_change_48_month_shift',\n",
    "    'female_40_to_44_annual_pct_change_36_month_shift',\n",
    "    'housing_units_10_to_19_units_annual_pct_change_36_month_shift',\n",
    "    'sales_tax_rate_annual_pct_change_12_month_shift',\n",
    "    'female_female_households_48_month_shift',\n",
    "    'women_with_associate_degree_annual_pct_change_36_month_shift',\n",
    "    'average_household_size_owners_annual_pct_change_36_month_shift',\n",
    "    'units_paying_cash_rent_annual_pct_change_36_month_shift',\n",
    "    'quintile_1_upper_limit_annual_pct_change_36_month_shift',\n",
    "    'Gross Value Natural Gas Production_13_month_shift',\n",
    "    'women_with_doctoral_degree_annual_pct_change_36_month_shift',\n",
    "    'total_sales_tax_annual_pct_change_12_month_shift',\n",
    "    'housing_units_built_1940_to_1949_36_month_shift',\n",
    "    'housing_units_built_1980_to_1989_annual_pct_change_36_month_shift',\n",
    "    'female_35_to_39_annual_pct_change_36_month_shift',\n",
    "    'bicycle_population_36_month_shift',\n",
    "    'housing_units_20_to_49_units_annual_pct_change_36_month_shift',\n",
    "    'taxpayer_count_12_month_shift',\n",
    "    'housing_units_5_to_9_units_36_month_shift',\n",
    "    'high_school_diploma_annual_pct_change_48_month_shift',\n",
    "    'driving_alone_population_annual_pct_change_36_month_shift',\n",
    "    'taxpayer_is_ratio_12_month_shift',\n",
    "    'motorcycle_population_36_month_shift',\n",
    "    'housing_units_single_family_attached_annual_pct_change_36_month_shift',\n",
    "    'white_pop_annual_pct_change_48_month_shift',\n",
    "    'taxpayer_cl_ratio_annual_pct_change_12_month_shift',\n",
    "    'taxpayer_is_ratio_annual_pct_change_12_month_shift',\n",
    "    'housing_units_built_1940_to_1949_annual_pct_change_36_month_shift',\n",
    "    'black_pop_annual_pct_change_48_month_shift',\n",
    "    'Gross Value Natural Gas Production_annual_pct_change_12_month_shift',\n",
    "    'housing_units_single_family_attached_owned_36_month_shift',\n",
    "    'single_women_annual_pct_change_36_month_shift',\n",
    "    'housing_units_built_1930_to_1939_36_month_shift',\n",
    "    'housing_units_built_1930_to_1939_annual_pct_change_36_month_shift',\n",
    "    'female_25_to_29_annual_pct_change_36_month_shift',    \n",
    "    'tx_net_approve_12_month_shift'\n",
    "    \n",
    "]\n",
    "y_val = 'zori_ssa'\n",
    "\n",
    "# split train and test based on a year in advance.\n",
    "train = merged_df.loc[merged_df['Time']<datetime.datetime(2020,7,2),:].reset_index(drop=True)\n",
    "post_train = merged_df.loc[merged_df['Time']>datetime.datetime(2020,7,2),:].reset_index(drop=True)\n",
    "test = post_train.loc[post_train['Time']<datetime.datetime(2021,7,2),:].reset_index(drop=True)\n",
    "forecast = post_train.loc[post_train['Time']>datetime.datetime(2021,7,2),:].reset_index(drop=True)\n",
    "\n",
    "# set up x and y values with a scaler\n",
    "# train first\n",
    "scaler = StandardScaler(with_mean=False)\n",
    "X = train[X_vals]\n",
    "X = scaler.fit_transform(X)\n",
    "y = train[y_val]\n",
    "# test second\n",
    "X_test = test[X_vals]\n",
    "X_test = scaler.transform(X_test)\n",
    "y_test = test[y_val]\n",
    "# forecasted values\n",
    "X_forecast = forecast[X_vals]\n",
    "X_forecast = scaler.transform(X_forecast)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7d4f7e",
   "metadata": {},
   "source": [
    "#### Construct model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1e2a9f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing Grid Search with alphas of: [0.1, 0.2, 0.3, 0.6, 1]\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Best alpha 0.1\n"
     ]
    }
   ],
   "source": [
    "lasso = Lasso(max_iter = 50000, random_state = 33)\n",
    "alphas = [0.1,0.2,0.3, 0.6, 1]\n",
    "tuned_parameters = [{'alpha': alphas}]\n",
    "print(f'Performing Grid Search with alphas of: {alphas}')\n",
    "clf = GridSearchCV(lasso, tuned_parameters, \n",
    "                    cv=5,n_jobs = -1, verbose=3,\n",
    "                  scoring = 'neg_root_mean_squared_error')\n",
    "# best_alpha = clf.best_params_['alpha']\n",
    "clf.fit(X, y)\n",
    "\n",
    "print(f\"Best alpha {clf.best_params_['alpha']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342155dd",
   "metadata": {},
   "source": [
    "#### Creating Coefficients of Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b58f9cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_df = pd.DataFrame({'features':test[X_vals].columns,'coefs':clf.best_estimator_.coef_})\n",
    "unselected_coef_df = coef_df[coef_df['coefs']==0]\n",
    "coef_df = coef_df[coef_df['coefs']!=0]\n",
    "coef_df['coefs_abs'] = abs(coef_df['coefs'])\n",
    "coef_df = coef_df.sort_values('coefs_abs',ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b227ccb",
   "metadata": {},
   "source": [
    "####  Feeding test values into model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc909f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = clf.predict(X_test)\n",
    "test.loc[:,'pred'] = y_pred_test\n",
    "test.loc[:,'pred_difference'] = test.loc[:,y_val] - y_pred_test\n",
    "\n",
    "rms = mean_squared_error(y_test, y_pred_test, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18ced987",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53.56478327318194"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c93706",
   "metadata": {},
   "source": [
    "####  Feeding forecast values into model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c1d87ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_fore = clf.predict(X_forecast)\n",
    "forecast.loc[:,'pred'] = y_pred_fore\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be090fc",
   "metadata": {},
   "source": [
    "#### Construct timeline of zori and what prediciton status they are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "90aa00b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-15-8466dcc37687>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  zori_pred_train['model_code'] = 'lasso_base'# just code for the lasso model\n",
      "<ipython-input-15-8466dcc37687>:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  zori_pred_fore['model_code'] = 'lasso_base'\n"
     ]
    }
   ],
   "source": [
    "# put actual data into correct format\n",
    "zori_pred_act = zri[['Time','zip_code','zori_ssa']].dropna(subset=['zori_ssa'])\n",
    "zori_pred_act['model_code'] = 'actual_values'\n",
    "# put train into correct format\n",
    "zori_pred_train = test[['Time','zip_code','pred']]\n",
    "zori_pred_train.columns = ['Time','zip_code','zori_ssa']\n",
    "zori_pred_train['model_code'] = 'lasso_base'# just code for the lasso model\n",
    "# put forecast into correct format\n",
    "zori_pred_fore = forecast[['Time','zip_code','pred']]\n",
    "zori_pred_fore.columns = ['Time','zip_code','zori_ssa']\n",
    "zori_pred_fore['model_code'] = 'lasso_base'\n",
    "# concat them together\n",
    "zori_pred = pd.concat([zori_pred_act, zori_pred_train, \n",
    "                       zori_pred_fore]).reset_index(drop=True)\n",
    "\n",
    "# zori_pred.to_csv('zori_pred_lasso_base.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f1aecc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
